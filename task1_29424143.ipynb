{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 1\n",
    "## Task 1: Parsing Raw Text Files\n",
    "#### Student Name: Harshavardhan Reddy Mallypally\n",
    "#### Student ID: 29424143\n",
    "\n",
    "Date: 31/07/2018\n",
    "\n",
    "Juypter version 5.5.0\n",
    "\n",
    "Environment: Python 3.6.0 and Anaconda 5.2.0 (64-bit)\n",
    "\n",
    "Packages used:\n",
    "* Regex (for regular expression, included in Anaconda Python 3.6)\n",
    "* Json package (for parsing jaspn doc, included in Anaconda Python 3.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "This task comprises the extracting data from unstructured text files. The raw text file containes information about the job advertisements, e.g., job title, job description, start date, required qualifications. Extracted data has to be transformed\n",
    "to the XML and JSON format.\n",
    "\n",
    "Sub-tasks are explained in following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Examining and Loading the data\n",
    "\n",
    "The file \"29424143.dat\" containes unstructured text file of job  advertisements, e.g., job title, job description, start date, required qualifications and soon. \n",
    "\n",
    "Format of the text can be inferred from looking at the first 34 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 68483\n",
      "_LOCS: Yerevan, Armenia\n",
      "DEAD_LINE: 26 June 2015\n",
      "START DATE: 14 May 2014\n",
      "JOB_DESC: The main duty of the Senior QA Engineer will be\n",
      "automation and improvement of the software testing process.\n",
      "REQUIRED QUALIFICATIONS:\n",
      "- Higher education;\n",
      "- Algorithmic thinking;\n",
      "- Knowledge of programming languages or experience in scripting is a\n",
      "plus;\n",
      "- Ability to work with databases;\n",
      "- Knowledge of XML, HTML, PHP languages is a plus;\n",
      "- Knowledge of MySQL database is a plus;\n",
      "- Knowledge of the Armenian, English and Russian languages.\n",
      "PROCEDURES: Please email your CV to: market_market@...\n",
      "and mention the job title in the subject line of your email.\n",
      "Please clearly mention in your application letter that you learned of\n",
      "this job opportunity through Career Center and mention the URL of its\n",
      "website - www.careercenter.am, Thanks.\n",
      "_info:\n",
      "France Telecom is a telecommunications operator\n",
      "providing services to more than 170 million customers on five continents\n",
      "of the world of which 120 million under the Orange brand.\n",
      "Orange Armenia is starting its activity as the third operator in the\n",
      "mobile telecommunications sphere in Armenia.\n",
      "Visit www.orange.com for more information.\n",
      "title: Customer Service Specialist\n",
      "REMUNERATION: Competitive + sales and customer management bonus\n",
      "system\n",
      "JOB RESPONSIBILITIES:\n",
      "- Pay regular visits to doctors and pharmacists;\n",
      "- Plan and execute other marketing activities.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# opens \"29424143.dat\" file and prints the first 34 lines\n",
    "with open('29424143.dat','r') as file:\n",
    "    print('\\n'.join([file.readline().strip() for i in range(0, 34)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all jobs advertisements in file exarcted and splited at \"------------------------------\". So, each job advertisement is an element of jobs_data list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID: 30479\n",
      "APPLICATION_DL: 25 November 2014\n",
      "start_date: 28 April 2005\n",
      "DESCRIPTION: The Sr. System Administrator will serve as part of the\n",
      "IT team responsible for the daily operations of LinkGard environment. The\n",
      "qualified individual will be responsible for a wide array of services\n",
      "including provisioning, installation, configuration, and maintenance of\n",
      "hardware, software and related infrastructure. The individual must also\n",
      "be ready to accept management duties as the company is interested in\n",
      "individuals who can grow into an IT Manager.\n",
      "QUALIFICATION:\n",
      " - Bachelor's degree or Advanced Diploma in Communications, Administration\n",
      "or other relevant field;\n",
      "- At least two years of experience in administrative and logistics\n",
      "support in a development environment supporting a senior manager;\n",
      "- Proficiency in a wide range of software packages, including Word,\n",
      "Excel, Outlook and PowerPoint, and ability to use the internet for\n",
      "research purposes; \n",
      "- Experience handling sensitive and confidential information;\n",
      "- Experience independently drafting a range of documents including emails\n",
      "and letters;\n",
      "- Excellent telephone skills and ability to interact with management and\n",
      "other contacts with tact and sensitivity;\n",
      "- Ability to acquire knowledge of project policies and procedures;\n",
      "- Interest in public health issues;\n",
      "- Fluent in Armenian. Excellent English language skills.\n",
      "PROCEDURES: All interested candidates are requested to\n",
      "submit the cover letter and CV to Ms. Priscilla Thompson at:Priscilla.Thompson@... with copy to: anahit@.... Please write\n",
      "in subject: Application for CD Georgia and your full name.\n",
      "It is strongly recommended that all candidates visit website of Heifer\n",
      "International at: www.heifer.org and www.heifercaucasus.org prior to\n",
      "applying for the position.  \n",
      "Short-list candidates will be invited for interviews on April 20 and 21\n",
      "in Tbilisi. Time and location for interviews will be announced while\n",
      "contacting the short-list candidates.\n",
      "Please clearly mention in your application letter that you learned of\n",
      "this job opportunity through Career Center and mention the URL of its\n",
      "website - www.careercenter.am, Thanks.\n",
      "ABOUT COMPANY:\n",
      " World Vision Armenia works in 194 communities in six\n",
      "marzes of Armenia and in Yerevan supporting 25,000 children and their\n",
      "families. The Organization fulfills advocacy, healthcare, education,\n",
      "economic development, child protection and spiritual growth activities.\n",
      "WV Armenia operates mainly through its 10-15 years long term Area\n",
      "Development Programs (ADP) that are predominantly funded through child\n",
      "sponsorship. ADPs are focused on promoting child well-being through\n",
      "community participation and ownership.\n",
      "title: Chief Quality Officer\n",
      "SALARY: Ranging from AMD 200,000 to 3,000,000 according to\n",
      "the S/ O grades of the Bank remuneration scheme, based on the placement\n",
      "decision for each particular candidate.\n",
      "RESPONSIBILITY:\n",
      " Under the overall supervision of the FAO\n",
      "Representative in Armenia, the technical supervision of the Plant\n",
      "Production and Protection Division (AGP) and FAO-REU Plant Production and\n",
      "Protection Officer (LTO), in close collaboration with the Ministry of\n",
      "Agriculture, the national counterparts, the National Project Coordinator\n",
      "(NPC), the International Expert on Grape Production/ Team Leader will\n",
      "undertake the following duties:\n",
      "First mission (at the start of the project):\n",
      "- Assess the current situation of grape production in Armenia;\n",
      "- Identify technical production constraints to be overcome;\n",
      "- Contribute to the preparation of the detailed work plan for the\n",
      "duration of the project;\n",
      "- Review current propagation techniques and suggest innovations as\n",
      "required;\n",
      "- Identify locally available technologies and research results applicable\n",
      "in the project area for grape improvement and promote their effective\n",
      "transfer to the farmers;\n",
      "- Update the list of necessary equipment, material and supplies to be\n",
      "purchased, prepare technical specifications and arrange for their\n",
      "procurement;\n",
      "- Provide inputs for the preparation of the training programme;\n",
      "- Provide on-the-job training to national counterpart staff and farmers\n",
      "and organize practical demonstrations on grape production;\n",
      "- Advise on the institutions to be visited by study-tour participants;\n",
      "- Define timing for the second and third visits;\n",
      "- Prepare a mission report.\n",
      "Second mission:\n",
      "- Review progress of the project and suggest modifications to the work\n",
      "plan as required;\n",
      "- Verify the application of technical recommendations formulated during\n",
      "the previous visit;\n",
      "- Provide technical advice on grape plantation establishment and orchard\n",
      "management;\n",
      "- Demonstrate pruning of grape plants in different vineyards;\n",
      "- Prepare training material;\n",
      "- Conduct training courses on modern grape production techniques for\n",
      "technical staff and farmers;\n",
      "- Supervise the work of the national consultant and formulate technical\n",
      "recommendations as required;\n",
      "- Prepare a mission report.\n",
      "Third mission:\n",
      "- Verify the application of technical recommendations formulated during\n",
      "previous visits;\n",
      "- Conduct practical demonstrations for grape production;\n",
      "- Assess the status of the new grape plantations;\n",
      "- Provide technical advice on vineyard management;\n",
      "- Prepare training material;\n",
      "- Conduct training courses on modern grape production techniques for\n",
      "technical staff and farmers;\n",
      "- Prepare a mission report.\n",
      "Fourth mission (towards the end of the project):\n",
      "- Conduct the overall assessment of the projects achievements and\n",
      "formulate recommendations as required;\n",
      "- Assess the status of newly-established vineyards;\n",
      "- Prepare the draft terminal statement of the project;\n",
      "- Prepare a mission report.\n",
      "- Carry out any other activities relevant to this assignment;\n",
      "- After each mission, prepare a brief report summarizing the findings,\n",
      "conclusions and recommendations;\n",
      "- Deskwork covers drafting and reviewing guidelines, policy documents and\n",
      "training material.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# jobs_data containes job advertisements has its elements\n",
    "jobs_data=[] \n",
    "with open(\"29424143.dat\", \"r\") as file:\n",
    "    ads_text=file.read()\n",
    "jobs_data=ads_text.split('------------------------------')\n",
    "print(jobs_data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Extraction of Job ID's using Regex Expression\n",
    "\n",
    "#### Approach to find the final regex for job IDs\n",
    "  1. Intially, I come up regex <font color = \"blue\">re'\\d{5}'</font> to extract the job IDs. but later I found that my regex is trying not only to catch IDs but also other numbers as well.\n",
    "\n",
    "  2. Then, I came up with <font color = \"blue\">re'ID: \\d{5}'</font> regex but it captures 'ID:' as well. So, finally I used group capture on ID number i.e. <font color = \"blue\">re'ID:\\s(.*)'</font> which captures ID numbers instead of 'ID:'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID's Extraction and appending in ID list\n",
    "ID=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    temp=(re.findall(r'ID:\\s(\\d{5})',jobs_data[i]))\n",
    "    ID.append(temp[0]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Extraction of Job location's using Regex Expression\n",
    "#### Approach to find the final regex for Locations\n",
    "  1. I found that every location has <font color = \"blue\">'LOC'</font> text in it and ends with mostly \"word, word\" format. So, I thought of regex <font color = \"blue\">re'LOC\\w{0,7}: (\\w{2,10}, \\w{2,10})'</font> would extract lot of locations. but I found few peculiar cases where this regex is not valid.\n",
    "  2. My regex isn't catching \"Yerevan (and other cities), Armenia\" this kind of location. To overcome that I updated my regex to\n",
    "<font color = \"blue\">re'LOC\\w{0,7}: (\\w{2,10}.\\*|, \\w{2,10})'</font>.\n",
    "  3. Finally, there are wide range of location format for example: <font color = \"blue\">\"Vanadzor, Lori region, Armenia\"</font>,\n",
    "<font color = \"blue\">\"Yerevan (50 %), Meghri (50 %), Armenia\"</font>. So, finally I used this regex <font color = \"blue\"> \"LOC\\w{0,7}: (.\\*)\"</font>. Now I can extract all the locations of different formats.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location's Extraction and  appending in location list\n",
    "location=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    loca_regex = (re.findall(r'LOC\\w{0,7}: (.*)',jobs_data[i]))\n",
    "    if loca_regex == []:\n",
    "        location.append('N\\A')\n",
    "    else:\n",
    "        location.append(loca_regex[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Extraction of Job deadline's using Regex Expression\n",
    "#### Approach to find the final regex for application deadlines\n",
    "   1. Initially, I found that the deadlines starts with <font color = \"blue\">'DEAD_LINES'</font> and <font color=\"blue\">'DEADLINES'</font> two formats so I created <font color = \"blue\">re'DEAD.\\*:.\\*'</font> has my intial regex.\n",
    "   2. Later, I found that there are other two types of deadlines starts with <font color = \"blue\">'APPLICATION_DL'</font> and <font color = \"blue\">'APPLICATION_DEADL'</font>. So, I changed my regex to <font color = \"blue\">re'APP\\w{2,8}_D\\w{1,4}:.\\* | DEAD.\\*:.\\*'</font>.\n",
    "   3. Finally, I captured the deadlines of all kind by taking using capturing group on my regex i.e. <font color = \"blue\">re'(APP\\w{2,8}_D\\w{1,4}:.\\*|DEAD.\\*:.\\*)'</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Flags not at the start of the expression '(APP\\\\w{2,8}_D\\\\w{1,4}' (truncated)\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# deadline's Extraction and appendind in raw_deadline list\n",
    "raw_deadline=[]\n",
    "deadline=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    dead_regex = (re.findall(r'(APP\\w{2,8}_D\\w{1,4}:.*|DEAD_LINE:.*|(?i)DEADLINE\\w{0,1}:.*)',jobs_data[i]))\n",
    "    if dead_regex == []:\n",
    "        raw_deadline.append('N/A')\n",
    "    else:\n",
    "        raw_deadline.append(dead_regex[0])\n",
    "        \n",
    "# further extraction to get data after colon. \n",
    "for i in raw_deadline:\n",
    "    date_regex = (re.findall(r': (.*)',i))\n",
    "    if date_regex == []:\n",
    "        deadline.append('N/A')\n",
    "    else:\n",
    "        deadline.append(date_regex[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Extraction of Job title's using Regex Expression\n",
    "#### Approach to find the final regex for titles\n",
    "1. Initially, I found that titles starts with <font color =\"blue\">'TITLES'</font> and <font color=\"blue\">'title'</font> two formats So I created <font color =\"blue\">re'(?i)TITLE\\w{0,1}:.\\*'</font> has my regex.\n",
    "2. Later, I found that there are other two types of titles starting with <font color=\"blue\">JOB_T</font> and <font color =\"blue\">_TTL</font>. So, I changed my regex to <font color =\"blue\">r'(JOB_T:.\\*|TTL:.\\*)</font> to capture title starting with above mentioned title headings.\n",
    "3. Finally, I captured all the titles by using capturing group on my regex i.e. <font color =\"blue\">r'(JOB_T:.\\*|TTL:.\\*|(?i)TITLE\\w{0,1}:.\\*)'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Flags not at the start of the expression '(JOB_T:.*|TTL:.*|(?i' (truncated)\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# titles's Extraction and appending in raw_titles list\n",
    "raw_titles=[]\n",
    "title=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    titles_regex = (re.findall(r'(JOB_T:.*|TTL:.*|(?i)TITLE\\w{0,1}:.*)',jobs_data[i]))\n",
    "    if titles_regex == []:\n",
    "        raw_titles.append('N/A')\n",
    "    else:\n",
    "        raw_titles.append(titles_regex[0])\n",
    "\n",
    "# further extraction to get data after colon.\n",
    "for i in raw_titles:\n",
    "    title_regex = (re.findall(r': (.*)',i))\n",
    "    if title_regex == []:\n",
    "        title.append('N/A')\n",
    "    else:\n",
    "        title.append(title_regex[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Extraction of Job salary's using Regex Expression\n",
    "#### Approach to find the final regex for salarys\n",
    "1. Initially, I found that titles starts with <font color =\"blue\">salary, SALARY, REMUNERATION, remuneration and JOB_SAL</font> four formats So I created <font color =\"blue\">(\\n(?i)salary:(?:.\\*?[A-Z]:(?s))|(?i)remuneration:(?:.\\*?[A-z]:(?s))|JOB_SAL:(?:.\\*?[A-Z]:(?s))'</font> has my regex. since the extarct is not limited to one line. I need to make sure all the text is captured so I used dotall flag to capture upto the next colon.\n",
    "2. Later, I found that extra data at the end can be removed at new line so I removed text after the last new line.\n",
    "3. Finally, I found that few job ads are ending with salary then my regex won't capture such text to overcome I created my final <font color =\"blue\">r'(\\n(?i)salary:(?:.\\*?[A-Z]:(?s)|.\\*(?s))|(?i)remuneration:(?:.\\*?[A-z]:(?s)|.\\*(?s))|JOB_SAL:(?:.\\*?[A-Z]:(?s)|.\\*(?s)))',</font>regex which captured to a great extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Flags not at the start of the expression '(\\\\n(?i)salary:(?:.*?' (truncated)\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# salary's Extraction and appending in raw_salary list\n",
    "raw_salary=[]\n",
    "salary=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    salarys_regex = (re.findall(r'(\\n(?i)salary:(?:.*?[A-Z]:(?s)|.*(?s))|(?i)remuneration:(?:.*?[A-z]:(?s)|.*(?s))|JOB_SAL:(?:.*?[A-Z]:(?s)|.*(?s)))',jobs_data[i]))\n",
    "    if salarys_regex == []:\n",
    "        raw_salary.append('N/A')\n",
    "    else:\n",
    "        raw_salary.append(salarys_regex[0])\n",
    "\n",
    "# further extraction to remove data after last new line and extracting data after colon.\n",
    "for i in range(0,len(raw_salary)-1):\n",
    "    count=0\n",
    "    for j in raw_salary[i]:\n",
    "        if j == '\\n':\n",
    "            count+=1\n",
    "    if count!=0:\n",
    "        temp=raw_salary[i].split('\\n')\n",
    "        new_salary=\" \".join(temp[0:len(temp)-1])\n",
    "        sal_regex = (re.findall(r': (.*)',new_salary))\n",
    "        if sal_regex == []:\n",
    "            salary.append('N/A')\n",
    "        else:\n",
    "            salary.append(sal_regex[0])\n",
    "    else:\n",
    "        salary.append(raw_salary[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Extraction of Job startdate's using Regex Expression\n",
    "#### Approach to find the final regex for startdate\n",
    "1. Initially, I found that startdates starts with <font color =\"blue\">START_DA, DATE_START, START_DATE,start_date and DATES</font> four formats So I created <font color =\"blue\">r'((?i)START[\\s\\S](?i)DA\\w{0,2}:.\\*|DATES:.\\*|DATE_START:.\\*)'</font> has my regex. since the extarct is not limited to one line. I need to make sure all the text is captured so I used dotall flag to capture upto the next colon.\n",
    "3. Later, I found that few job ads are ending with startdate and colon then my regex won't capture such text to overcome I created my final <font color =\"blue\">r'((?i)START[\\s\\S](?i)DA\\w{0,2}:.\\*?:(?s)|DATES:.\\*?:(?s)|DATE_START:.\\*?:(?s))'</font>regex which captured to a great extent.\n",
    "3. Finally, I found that extra data at the end can be removed at new line so I removed text after the last new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Flags not at the start of the expression '((?i)START[\\\\s\\\\S](?i)' (truncated)\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# startdate's Extraction and appending in raw_startdate list\n",
    "raw_startdate=[]\n",
    "startdate=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    start_regex = (re.findall(r'((?i)START[\\s\\S](?i)DA\\w{0,2}:.*?:(?s)|DATES:.*?:(?s)|DATE_START:.*?:(?s))',jobs_data[i]))\n",
    "    if start_regex == []:\n",
    "        raw_startdate.append('N/A')\n",
    "    else:\n",
    "        raw_startdate.append(start_regex[0])\n",
    "        \n",
    "# further extraction to remove data after last new line and extracting data after colon.\n",
    "for i in range(0,len(raw_startdate)-1):\n",
    "    count=0\n",
    "    for j in raw_startdate[i]:\n",
    "        if j == '\\n':\n",
    "            count+=1\n",
    "    if count!=0:\n",
    "        temp=raw_startdate[i].split('\\n')\n",
    "        new_temp=temp[0:len(temp)-1]\n",
    "        new_startdate=\" \".join(temp[0:len(temp)-1])\n",
    "        start_regex = (re.findall(r': (.*)',new_startdate))\n",
    "        if start_regex == []:\n",
    "            startdate.append('N/A')\n",
    "        else:\n",
    "            startdate.append(start_regex[0])\n",
    "    else:\n",
    "        startdate.append(raw_startdate[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Extraction of Job About company's using Regex Expression\n",
    "#### Approach to find the final regex for company details\n",
    "1. Initially, I found that about_company starts with <font color =\"blue\">ABOUT, ABOUT COMPANY, _info,COMPANYS_INFO and about_company</font> four formats So I created <font color =\"blue\">r'((?i)ABOUT(?:[\\s|\\S]\\w{0,7}|):(?:.\\*?\\.\\n(?s))|(?i)_info:(?:.\\*?\\.\\n(?s)))'</font> has my regex. since the extarct is not limited to one line. I need to make sure all the text is captured so I used dotall flag to capture upto the next colon.\n",
    "2. Later, I found that few job ads are ending with just aboutcompany format and colon then my regex won't capture such text to overcome I created my final <font color =\"blue\">r'((?i)ABOUT(?:[\\s|\\S]\\w{0,7}|):(?:.\\*?\\.\\n(?s)|.\\*(?s))|(?i)_info:(?:.\\*?\\.\\n(?s)|.\\*(?s)))</font>regex which captured to a great extent.\n",
    "3. eventhough I captured a lot for data perfectly I found few are empty so I created a empty data capturing regex <font color =\"blue\">r'(((?i)ABOUT(?:[\\s|\\S]\\w{0,7}|):\\s{3}|(?i)INFO:\\s{3}))</font>.\n",
    "4. Finally, I found that extra data at the end can be removed at new line so I removed text after the last new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Flags not at the start of the expression '((?i)ABOUT(?:[\\\\s|\\\\S]' (truncated)\n",
      "  \n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Flags not at the start of the expression '(((?i)ABOUT(?:[\\\\s|\\\\S' (truncated)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# companyinfo's Extraction and appending in raw_company list\n",
    "raw_companyinfo=[]\n",
    "Raw_companyinfo=[]\n",
    "companyinfo=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    info_regex = (re.findall(r'((?i)ABOUT(?:[\\s|\\S]\\w{0,7}|):(?:.*?\\.\\n(?s)|.*(?s))|(?i)_info:(?:.*?\\.\\n(?s)|.*(?s)))',jobs_data[i]))\n",
    "    if info_regex == []:\n",
    "        raw_companyinfo.append('N/A')\n",
    "    else:\n",
    "        raw_companyinfo.append(info_regex[0])\n",
    "\n",
    "# further refining by removing missing data value       \n",
    "for i in range(0,len(raw_companyinfo)):\n",
    "    empty_regex = (re.findall(r'(((?i)ABOUT(?:[\\s|\\S]\\w{0,7}|):\\s{3}|(?i)INFO:\\s{3}))',raw_companyinfo[i]))\n",
    "    if empty_regex == []:\n",
    "        Raw_companyinfo.append(raw_companyinfo[i])\n",
    "    else:\n",
    "        Raw_companyinfo.append('N/A')\n",
    "        \n",
    "# further extraction to remove data after last new line and extracting data after colon.\n",
    "for i in range(0,len(Raw_companyinfo)):\n",
    "    count=0\n",
    "    for j in Raw_companyinfo[i]:\n",
    "        if j == '\\n':\n",
    "            count+=1\n",
    "    if count!=0:\n",
    "        temp=Raw_companyinfo[i].split('\\n')\n",
    "        new_temp=temp[0:len(temp)-1]\n",
    "        new_companyinfo=\" \".join(temp[0:len(temp)-1])\n",
    "        company_regex = (re.findall(r': (.*)',new_companyinfo))\n",
    "        if company_regex == []:\n",
    "            companyinfo.append('N/A')\n",
    "        else:\n",
    "            companyinfo.append(company_regex[0])\n",
    "    else:\n",
    "        companyinfo.append(Raw_companyinfo[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Extraction of Job Responsibilities's using Regex Expression\n",
    "#### Approach to find the final regex for job responsibilities\n",
    "1. Initially, I found that job_responsibilities starts with <font color =\"blue\">RESPONSIBILITIES, responsibilities, RESP and RESPS</font> four formats So I created <font color =\"blue\">r'((?i)RESPONSIBILIT\\w{1,3}:(?:.\\*(?s))|RESP(?:S|):(?:.\\*?(?s)))</font> has my regex. since the extarct is not limited to one line. I need to make sure all the text is captured so I used dotall flag to capture upto the next colon.\n",
    "2. I have great advantage on the responsibilities is that all my job ads are ending with responsibilities so I can extract them very easily with a simple regex mentioned above.\n",
    "3. From, looking into the sample xml and json file I found that job responsibilites are sub divided into responsibilities. So, I have came up with this new regex <font color =\"blue\"> r'(?:(?:-|\\w{1}[)])(.\\*?(?s))(?:;|\\.|,|\\n-))'</font>. which is applied on the job responsibilites that I extract using the above regex.\n",
    "4. To capture more of that data I created another regex  <font color =\"blue\">r':(?:\\s|\\s\\s|\\s\\n\\s|\\s\\n\\s\\s)(.\\*)(?s)(?:\\n)' </font>\n",
    "5. Finally, I found that extra data at the end can be removed at new line so I removed text after the last new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Flags not at the start of the expression '((?i)RESPONSIBILIT\\\\w' (truncated)\n",
      "  \"\"\"\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Flags not at the start of the expression '(?:(?:-|\\\\w{1}[)])(.*' (truncated)\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Flags not at the start of the expression ':(?:\\\\s|\\\\s\\\\s|\\\\s\\\\n\\\\s|\\\\' (truncated)\n"
     ]
    }
   ],
   "source": [
    "# job_responsibilities's Extraction and appending in raw_responsibilities list\n",
    "raw_responsibility=[]\n",
    "responsibility=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    resp_regex = (re.findall(r'((?i)RESPONSIBILIT\\w{1,3}:(?:.*(?s))|RESP(?:S|):(?:.*?(?s)))',jobs_data[i]))\n",
    "    if resp_regex == []:\n",
    "        #print(str(jobs_data[i])+ '\\n')\n",
    "        raw_responsibility.append('N/A')\n",
    "    else:\n",
    "        raw_responsibility.append(resp_regex[0])\n",
    "\n",
    "# finding individual responsibities in raw_responsibility list \n",
    "for i in range(0,(len(raw_responsibility)-1)):\n",
    "    if raw_responsibility[i]=='N/A':\n",
    "        responsibility.append('N/A')\n",
    "    else:\n",
    "        resps_regex=(re.findall(r'(?:(?:-|\\w{1}[)])(.*?(?s))(?:;|\\.|,|\\n-))',raw_responsibility[i]))\n",
    "        if resps_regex == []:\n",
    "            respos_regex=(re.findall(r':(?:\\s|\\s\\s|\\s\\n\\s|\\s\\n\\s\\s)(.*)(?s)(?:\\n)',raw_responsibility[i]))\n",
    "            if respos_regex == []:\n",
    "                responsibility.append('N/A')\n",
    "            elif respos_regex == [' ']:\n",
    "                responsibility.append('N/A')\n",
    "            else:\n",
    "                responsibility.append(respos_regex)\n",
    "        else:\n",
    "            responsibility.append(resps_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Extraction of Job Qualification's using Regex Expression\n",
    "#### Approach to find the final regex for job qualifications\n",
    "1. Initially, I found that job_qualification starts with <font color =\"blue\">QUALIFICATION, QUALIFS, REQUIRED QUALIFICATION, REQ_QUALS and qualification</font> four formats So I created <font color =\"blue\">r'(QUAL(?:IFICATION|IFS|IFICATIONS|S):.\\*?[A-Z]{1}[:|/](?s)|\\nqualifications:.\\*?[A-Z]{1}[:|/](?s))'</font> has my regex. since the extarct is not limited to one line. I need to make sure all the text is captured so I used dotall flag to capture upto the next colon.\n",
    "2. From, looking into the sample xml and json file I found that job qualifications are sub divided into qualifications. So, I have came up with this new regex <font color =\"blue\"> r'(?:(?:-)(.\\*?(?s))(?:;|\\.|\\s-))'</font>. which is applied on the job qualifications that I extract using the above regex.\n",
    "4. To capture more of that data I created another regex  <font color =\"blue\">r':(\\s{3}(?:\\S\\w{4}|\\w{5}\\S\\w{7}|\\w{10}))[:|/]' </font>\n",
    "5. Finally, I found that extra data at the end can be removed at new line so I removed text after the last new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Flags not at the start of the expression '(QUAL(?:IFICATION|IF' (truncated)\n",
      "  \n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:35: DeprecationWarning: Flags not at the start of the expression '(?:(?:-)(.*?(?s))(?:' (truncated)\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:37: DeprecationWarning: Flags not at the start of the expression ':(.*(?s))'\n"
     ]
    }
   ],
   "source": [
    "# job_qualification's Extraction and appending in raw_qualification list\n",
    "raw_qualification=[]\n",
    "Raw_quals=[]\n",
    "qual=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    quals_regex = (re.findall(r'(QUAL(?:IFICATION|IFS|IFICATIONS|S):.*?[A-Z]{1}[:|/](?s)|\\nqualifications:.*?[A-Z]{1}[:|/](?s))',jobs_data[i]))\n",
    "    if quals_regex == []:\n",
    "        raw_qualification.append('N/A')\n",
    "    else:\n",
    "        raw_qualification.append(quals_regex[0])\n",
    "        \n",
    "# further extraction to remove data after last new line and extracting data after colon.\n",
    "for i in range(0,len(raw_qualification)):\n",
    "    count=0\n",
    "    for j in raw_qualification[i]:\n",
    "        if j == '\\n':\n",
    "            count+=1\n",
    "    if count!=0:\n",
    "        temp=raw_qualification[i].split('\\n')\n",
    "        new_temp=temp[0:len(temp)-1]\n",
    "        new_quals=\" \".join(temp[0:len(temp)-1])\n",
    "        quals_regex = (re.findall(r'(.*)',new_quals))\n",
    "        if quals_regex == []:\n",
    "            Raw_quals.append('N/A')\n",
    "        else:\n",
    "            Raw_quals.append(quals_regex[0])\n",
    "    else:\n",
    "        Raw_quals.append(raw_qualification[i])\n",
    "        \n",
    "# finding individual qualifications in Raw_qualifications list \n",
    "for i in range(0,len(Raw_quals)):\n",
    "    if Raw_quals[i]=='N/A':\n",
    "        qual.append('N/A')\n",
    "    else:\n",
    "        quali_regex=(re.findall(r'(?:(?:-)(.*?(?s))(?:;|\\.|\\s-))',Raw_quals[i]))\n",
    "        if quali_regex == []:\n",
    "            qualis_regex=(re.findall(r':(.*(?s))',Raw_quals[i]))\n",
    "            if qualis_regex == ['  ']:\n",
    "                qual.append('N/A')\n",
    "            elif qualis_regex == ['']:\n",
    "                qual.append('N/A')\n",
    "            else:\n",
    "                match_pattern=re.findall(r':(\\s{3}(?:\\S\\w{4}|\\w{5}\\S\\w{7}|\\w{10}))[:|/]',Raw_quals[i])\n",
    "                if match_pattern!=[]:\n",
    "                    qual.append('N/A')\n",
    "                else:\n",
    "                    qual.append(qualis_regex)\n",
    "        else:\n",
    "            qual.append(quali_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Extraction of Job Description's using Regex Expression\n",
    "#### Approach to find the final regex for job description\n",
    "1. Initially, I found that job_qualification starts with <font color =\"blue\">JOB_DESC, JOB DESCRIPTION, DESCRIPTION,job_desc,_description</font> four formats So I created <font color =\"blue\">r'(DES(?:CRIPTION|C):.\\*?[A-Z]{1,5}[:|/](?s)|des(?:cription|c):.\\*?[A-Z]{1,5}[:|/](?s))'</font> has my regex. since the extarct is not limited to one line. I need to make sure all the text is captured so I used dotall flag to capture upto the next colon.\n",
    "2. From, looking into the sample xml and json file I found that job description are sub divided into description. So, I have came up with this new regex <font color =\"blue\"> r'((?:\\w{1,20}|\\S|\\s).\\*(?s))'</font>. which is applied on the job description that I extract using the above regex.\n",
    "3. To capture missing values for different format data I created another regex  <font color =\"blue\">r': ((?i)N/A|N/|NA|H/A)'.</font>\n",
    "5. Finally, I found that extract data at the end can be removed at new line so I removed text after the last new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Flags not at the start of the expression '(DES(?:CRIPTION|C):.' (truncated)\n",
      "  \n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:37: DeprecationWarning: Flags not at the start of the expression ':(.*?(?s)\\\\.)'\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:39: DeprecationWarning: Flags not at the start of the expression ': ((?i)N/A|N/|NA|H/A' (truncated)\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:41: DeprecationWarning: Flags not at the start of the expression ': ((?:\\\\w{1,20}|\\\\S|\\\\s' (truncated)\n"
     ]
    }
   ],
   "source": [
    "# job_description's Extraction and appending in raw_description list\n",
    "raw_desc=[]\n",
    "Raw_desc=[]\n",
    "desc=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    desc_regex = (re.findall(r'(DES(?:CRIPTION|C):.*?[A-Z]{1,5}[:|/](?s)|des(?:cription|c):.*?[A-Z]{1,5}[:|/](?s))',jobs_data[i]))\n",
    "    if desc_regex == []:\n",
    "        raw_desc.append(['N/A'])\n",
    "    else:\n",
    "        raw_desc.append(desc_regex[0])\n",
    "        \n",
    "# further extraction to remove data after last new line and extracting data after colon.\n",
    "for i in range(0,len(raw_desc)):\n",
    "    count=0\n",
    "    for j in str(raw_desc[i]):\n",
    "        if j == '\\n':\n",
    "            count+=1\n",
    "    if count!=0:\n",
    "        #print(raw_desc[i])\n",
    "        temp=raw_desc[i].split('\\n')\n",
    "        new_temp=temp[0:len(temp)-1]\n",
    "        new_descs=\" \".join(temp[0:len(temp)-1])\n",
    "        descss_regex = (re.findall(r'(.*)',new_descs))\n",
    "        if descss_regex == []:\n",
    "            Raw_desc.append('N/A')\n",
    "        else:\n",
    "            Raw_desc.append(descss_regex)\n",
    "    else:\n",
    "        #print(raw_desc[i])\n",
    "        Raw_desc.append(raw_desc[i])\n",
    "\n",
    "# finding individual descriptions in Raw_descriptions list       \n",
    "for i in range(0,len(Raw_desc)):\n",
    "    if Raw_desc[i]=='N/A':\n",
    "        desc.append(['N/A'])\n",
    "    else:\n",
    "        descr_regex=(re.findall(r':(.*?(?s)\\.)',str(Raw_desc[i])))\n",
    "        if descr_regex == []:\n",
    "            match_pat=re.findall(r': ((?i)N/A|N/|NA|H/A)',str(Raw_desc[i]))\n",
    "            if match_pat==[]:\n",
    "                match_pat1=(re.findall(r': ((?:\\w{1,20}|\\S|\\s).*(?s))',str(Raw_desc[i])))\n",
    "                if match_pat1==[]:\n",
    "                    desc.append(['N/A'])\n",
    "                else:\n",
    "                    desc.append(match_pat1)\n",
    "            else:\n",
    "                desc.append(['N/A'])\n",
    "        else:\n",
    "            desc.append(descr_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 Extraction of application procedure using Regex Expression\n",
    "#### Approach to find the final regex for application procedure\n",
    "1. Initially, I found that application_procedure starts with <font color =\"blue\">JOB_PROC,PROCEDURE,PROCEDURES,JOB_PROCS and procedures</font> four formats So I created <font color =\"blue\">r'(PRO(?:CEDURES|C|CS|CEDURE):.\\*?[A-Z]{1}[:|/](?s)|pro(?:cedures):.\\*?[A-Z]{1}[:|/](?s))'</font> has my regex. since the extract is not limited to one line. I need to make sure all the text is captured so I used dotall flag to capture upto the next colon.\n",
    "2. unlike, job_responsibilities,job qualification application procedure has only a string of information with sub division which made my work easy at the same time hard since I have so many procedures ending with _info: which I removed using the  <font color =\"blue\">r':(.\\*?(?s)\\.)(?:\\n_info:|\\n\\w{5,10}:)'</font> \n",
    "3. Finally, I found that extra data at the end can be removed at new line so I removed text after the last new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Flags not at the start of the expression '(PRO(?:CEDURES|C|CS|' (truncated)\n",
      "  \n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Flags not at the start of the expression '(.*(?s))'\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:36: DeprecationWarning: Flags not at the start of the expression ':(.*?(?s)\\\\.)(?:\\\\n_in' (truncated)\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:39: DeprecationWarning: Flags not at the start of the expression ': (.*(?s)\\\\.)'\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:41: DeprecationWarning: Flags not at the start of the expression ': (.*(?s))'\n"
     ]
    }
   ],
   "source": [
    "# job_procedure's Extraction and appending in raw_procedure list\n",
    "raw_proc=[]\n",
    "Raw_proc=[]\n",
    "proc=[]\n",
    "for i in range(0,(len(jobs_data)-1)):\n",
    "    proc_regex = (re.findall(r'(PRO(?:CEDURES|C|CS|CEDURE):.*?[A-Z]{1}[:|/](?s)|pro(?:cedures):.*?[A-Z]{1}[:|/](?s))',jobs_data[i]))\n",
    "    if proc_regex == []:\n",
    "        raw_proc.append('N/A')\n",
    "    else:\n",
    "        raw_proc.append(proc_regex[0])\n",
    "        \n",
    "# further extraction to remove data after last new line and extracting data after colon.\n",
    "for i in range(0,len(raw_proc)):\n",
    "    count=0\n",
    "    for j in raw_proc[i]:\n",
    "        if j == '\\n':\n",
    "            count+=1\n",
    "    if count!=0:\n",
    "        temp=raw_proc[i].split('\\n')\n",
    "        new_temp=temp[0:len(temp)-1]\n",
    "        new_procs=\"\\n\".join(temp[0:len(temp)-1])\n",
    "        procs_regex = (re.findall(r'(.*(?s))',new_procs))\n",
    "        if procs_regex == []:\n",
    "            Raw_proc.append(['N/A'])\n",
    "        else:\n",
    "            Raw_proc.append(procs_regex[0])\n",
    "    else:\n",
    "        Raw_proc.append(raw_proc[i])\n",
    "\n",
    "# finding individual procedures in Raw_procedures list           \n",
    "for i in range(0,len(Raw_proc)):\n",
    "    if Raw_proc[i]=='N/A':\n",
    "        proc.append(['N/A'])\n",
    "    else:\n",
    "        #print(str(Raw_proc[i])+'\\n')\n",
    "        proce_regex=(re.findall(r':(.*?(?s)\\.)(?:\\n_info:|\\n\\w{5,10}:)',Raw_proc[i]))\n",
    "        if proce_regex == []:\n",
    "            #print(str(Raw_proc[i])+'\\n'+str(ID[i])+'\\n'+str(proce_regex)+'\\n\\n')\n",
    "            math_pat=re.findall(r': (.*(?s)\\.)',Raw_proc[i])\n",
    "            if math_pat==[]:\n",
    "                math_pat1=re.findall(r': (.*(?s))',Raw_proc[i])\n",
    "                if math_pat1==[]:\n",
    "                    proc.append(['N/A'])\n",
    "                else:\n",
    "                    proc.append(math_pat1)\n",
    "            else:\n",
    "                proc.append(math_pat)\n",
    "        else:\n",
    "            proc.append(proce_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. FILE CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 XML FILE CREATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#created xml file and opened in write mode\n",
    "text = open(\"29424143.xml\", \"w\")\n",
    "\n",
    "# xml tags and their relevant data is written into the file\n",
    "text.write('<listings>')\n",
    "text.write('\\n\\t')\n",
    "for i in range(0,(len(ID)-1)):\n",
    "    text.write('<listing id='+'\\''+ID[i]+'\\''+'>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    \n",
    "    text.write('<title>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    titl=title[i].replace(\"&\",\"&amp;\")\n",
    "    text.write(titl)\n",
    "    text.write('\\n\\t\\t')\n",
    "    text.write('</title>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    \n",
    "    text.write('<location>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    text.write(location[i].replace(\"&\",\"&amp;\"))\n",
    "    text.write('\\n\\t\\t')\n",
    "    text.write('</location>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    \n",
    "    text.write('<job_description>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    if (len(desc[i]) == 1 and desc[i][0] == '[\"N/A\"]') or desc[i] == 'N/A':\n",
    "        text.write('<description>')\n",
    "        text.write('\\n\\t\\t\\t')\n",
    "        job_dec = str(desc[i]).replace(\"&\",\"&amp;\")\n",
    "        text.write(job_dec)\n",
    "        text.write('\\n\\t\\t\\t')\n",
    "        text.write('</description>')\n",
    "        text.write('\\n\\t\\t\\t')                            \n",
    "    else:\n",
    "        for txt in desc[i]:\n",
    "            text.write('<description>')\n",
    "            text.write('\\n\\t\\t\\t')\n",
    "            job_dec = str(txt).replace(\"&\",\"&amp;\")\n",
    "            text.write(job_dec)\n",
    "            text.write('\\n\\t\\t\\t')\n",
    "            text.write('</description>')\n",
    "    text.write('</job_description>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    \n",
    "    text.write('<job_responsibilities>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    if (len(responsibility[i]) == 1 and responsibility[i] == '[\"N/A\"]') or responsibility[i] == 'N/A':\n",
    "        text.write('<responsibilities>')\n",
    "        text.write('\\n\\t\\t\\t')\n",
    "        job_rep = str(responsibility[i]).replace(\"&\",\"&amp;\")\n",
    "        text.write(job_rep)\n",
    "        text.write('\\n\\t\\t\\t')\n",
    "        text.write('</responsibilities>')\n",
    "        text.write('\\n\\t\\t')\n",
    "    else:\n",
    "        for txt in responsibility[i]:\n",
    "            text.write('<responsibilities>')\n",
    "            text.write('\\n\\t\\t\\t')\n",
    "            job_rep = str(txt).replace(\"&\",\"&amp;\")\n",
    "            text.write(job_rep)\n",
    "            text.write('\\n\\t\\t\\t')\n",
    "            text.write('</responsibilities>')\n",
    "            text.write('\\n\\t\\t')\n",
    "    text.write('</job_responsibilities>')\n",
    "    text.write('\\n\\t\\t')\n",
    "  \n",
    "    text.write('<required_qualifications>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    if (len(qual[i]) == 1 and qual[i][0] == '[\"N/A\"]') or qual[i] == 'N/A':\n",
    "        text.write('<qualification>')\n",
    "        text.write('\\n\\t\\t\\t')\n",
    "        job_qual = str(qual[i]).replace(\"&\",\"&amp;\")\n",
    "        text.write(job_qual)\n",
    "        text.write('\\n\\t\\t\\t')\n",
    "        text.write('</qualification>')\n",
    "        text.write('\\n\\t\\t')\n",
    "    else:\n",
    "        for txt in qual[i]:\n",
    "            text.write('<qualification>')\n",
    "            text.write('\\n\\t\\t\\t')\n",
    "            job_rep = str(txt).replace(\"&\",\"&amp;\")\n",
    "            text.write(job_rep)\n",
    "            text.write('\\n\\t\\t\\t')\n",
    "            text.write('</qualification>')\n",
    "            text.write('\\n\\t\\t')\n",
    "    text.write('</required_qualifications>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    \n",
    "    text.write('<salary>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    job_sal = str(salary[i]).replace(\"&\",\"&amp;\")\n",
    "    text.write(job_sal)\n",
    "    text.write('\\n\\t\\t')\n",
    "    text.write('</salary>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    \n",
    "    text.write('<application_procedure>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    job_proc = str(proc[i]).replace(\"&\",\"&amp;\")\n",
    "    text.write(job_proc)\n",
    "    text.write('\\n\\t\\t')\n",
    "    text.write('</application_procedure>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    \n",
    "    text.write('<start_date>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    job_start = startdate[i].replace(\"&\",\"&amp;\")\n",
    "    text.write(job_start)\n",
    "    text.write('\\n\\t\\t')\n",
    "    text.write('</start_date>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    \n",
    "    text.write('<application_deadline>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    job_dead = deadline[i].replace(\"&\",\"&amp;\")\n",
    "    text.write(job_dead)\n",
    "    text.write('\\n\\t\\t')\n",
    "    text.write('</application_deadline>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    \n",
    "    text.write('<about_company>')\n",
    "    text.write('\\n\\t\\t\\t')\n",
    "    job_dead = companyinfo[i].replace(\"&\",\"&amp;\")\n",
    "    text.write(job_dead)\n",
    "    text.write('\\n\\t\\t')\n",
    "    text.write('</about_company>')\n",
    "    text.write('\\n\\t\\t')\n",
    "    text.write('</listing>')\n",
    "    text.write('\\n\\t')\n",
    "    \n",
    "    \n",
    "text.write('</listings>')\n",
    "# end of the tags all tags and data are written\n",
    "# closed the file\n",
    "text.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 4.2 JSON FILE CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created text file and opened in write mode\n",
    "text = open(\"29424143.txt\", \"w\")\n",
    "\n",
    "# all data is written in json format\n",
    "text.write('\"{')\n",
    "text.write('\"listings\"'+': {')\n",
    "for i in range(0,(len(ID)-1)):\n",
    "    text.write('\"listing\": [{')\n",
    "    \n",
    "    text.write('\"_id\" :'+'\"'+ID[i]+'\",')\n",
    "    \n",
    "    text.write('\"title\":'+'\"'+title[i]+'\",')\n",
    "    \n",
    "    text.write('\"location\":'+'\"'+location[i]+'\",')    \n",
    "    \n",
    "    text.write('\"job_descriptions\": {')\n",
    "    if (len(desc[i]) == 1 and desc[i][0] == '[\"N/A\"]') or desc[i] == 'N/A':\n",
    "        text.write('\"description\": [ \"'+str(desc[i])+'\" ]')\n",
    "    else:\n",
    "        text.write('\"description\": [')\n",
    "        count = 0\n",
    "        for txt in desc[i]:\n",
    "            if(count<len(desc[i])-1):\n",
    "                text.write('\"'+str(txt)+'\"')\n",
    "            else:\n",
    "                text.write('\"'+str(txt)+'\",')\n",
    "            count+=1\n",
    "    text.write(']')\n",
    "    text.write('},')\n",
    "    \n",
    "    text.write('\"job_responsibilities\": {')\n",
    "    if (len(responsibility[i]) == 1 and responsibility[i][0] == '[\"N/A\"]') or responsibility[i] == 'N/A':\n",
    "        text.write('\"responsibilities\": [ \"'+str(responsibility[i])+'\" ]')\n",
    "    else:\n",
    "        text.write('\"responsibilities\": [')\n",
    "        count = 0\n",
    "        for txt in responsibility[i]:\n",
    "            if(count<len(responsibility[i])-1):\n",
    "                text.write('\"'+str(txt)+'\"')\n",
    "            else:\n",
    "                text.write('\"'+str(txt)+'\",')\n",
    "            count+=1\n",
    "    text.write(']')\n",
    "    text.write('},')\n",
    "  \n",
    "    text.write('\"job_qualifications\": {')\n",
    "    if (len(qual[i]) == 1 and qual[i][0] == '[\"N/A\"]') or qual[i] == 'N/A':\n",
    "        text.write('\"qualification\": [ \"'+str(qual[i])+'\" ]')\n",
    "    else:\n",
    "        text.write('\"qualification\": [')\n",
    "        count = 0\n",
    "        for txt in qual[i]:\n",
    "            if(count<len(qual[i])-1):\n",
    "                text.write('\"'+str(txt)+'\"')\n",
    "            else:\n",
    "                text.write('\"'+str(txt)+'\",')\n",
    "            count+=1\n",
    "    text.write(']')\n",
    "    text.write('},')\n",
    "    \n",
    "    text.write('\"salary\":'+'\"'+salary[i]+'\",')\n",
    "    \n",
    "    text.write('\"application_procedures\":'+'\"'+str(proc[i])+'\",')\n",
    "    \n",
    "    text.write('\"start_date\":'+'\"'+startdate[i]+'\",')\n",
    "    \n",
    "    text.write('\"application_deadline\":'+'\"'+deadline[i]+'\",')\n",
    "    \n",
    "    text.write('\"about_company\":'+'\"'+companyinfo[i]+'\",')\n",
    "    text.write('}]')\n",
    "    text.write('}')\n",
    "text.write('}')\n",
    "text.close()\n",
    "\n",
    "# json format text file is opened in read mode\n",
    "myfile =  open(\"29424143.txt\",\"r\")\n",
    "to_json = myfile.read()\n",
    "\n",
    "# using JSON package dumped all the json format text \n",
    "tojson = json.dumps(to_json[2:])\n",
    "\n",
    "# json file is opened in write mode\n",
    "js = open(\"29424143.json\",\"w\")\n",
    "js.write(to_json[1:])\n",
    "# json file is closed after writing and also the text file\n",
    "js.close()\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SUMMARY\n",
    "\n",
    "1. Extracted all job adverstiments.\n",
    "2. Created the XML with no errors.\n",
    "3. Created the JSON with no errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
